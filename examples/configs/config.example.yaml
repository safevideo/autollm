# config.example.yaml
version: '2.0'  # Version of this configuration file
tasks:
  - name: "summarize"
    system_prompt: "You are an expert ai assistant specialized in summarization."  # System prompt for this task
    vector_store_params:
      vector_store_type: "SimpleVectorStore"
    embed_model: "default"  # ["default", "local"]
    llm_params:
      model: "gpt-3.5-turbo"
    service_context_params:
      chunk_size: 1024
    query_engine_params:
      similarity_top_k: 5
    enable_cost_calculator: true
  - name: "qa"
    system_prompt: "You are a friendly ai assistant specialized in question answering."  # System prompt for this task
    vector_store_params:
      vector_store_type: "SimpleVectorStore"
    embed_model: "default"  # ["default", "local"]
    llm_params:
      model: "gpt-4"
    service_context_params:
      chunk_size: 1024
    query_engine_params:
      similarity_top_k: 3
    enable_cost_calculator: false
